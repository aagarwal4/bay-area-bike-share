{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SQLContext\n",
    "from pyspark.sql.types  import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing DataFrame objects from MongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statusDF = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb://127.0.0.1/msan697.status\").load()\n",
    "\n",
    "stationDF = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb://127.0.0.1/msan697.station\").load()\n",
    "\n",
    "weatherDF = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb://127.0.0.1/msan697.weather\").load()\n",
    "\n",
    "tripDF = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb://127.0.0.1/msan697.trip\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------------+----------+-------------------+\n",
      "|                 _id|bikes_available|docks_available|station_id|               time|\n",
      "+--------------------+---------------+---------------+----------+-------------------+\n",
      "|[5a5d49a291bd3626...|              2|             25|         2|2013/08/29 12:06:01|\n",
      "|[5a5d49a291bd3626...|              2|             25|         2|2013/08/29 12:07:01|\n",
      "|[5a5d49a291bd3626...|              2|             25|         2|2013/08/29 12:08:01|\n",
      "|[5a5d49a291bd3626...|              2|             25|         2|2013/08/29 12:09:01|\n",
      "|[5a5d49a291bd3626...|              2|             25|         2|2013/08/29 12:10:01|\n",
      "+--------------------+---------------+---------------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statusDF.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+---+-----------------+------------------+-------------------+--------------------+\n",
      "|                 _id|    city|dock_count| id|installation_date|               lat|               long|                name|\n",
      "+--------------------+--------+----------+---+-----------------+------------------+-------------------+--------------------+\n",
      "|[5a5d498991bd3626...|San Jose|        19|  5|         8/5/2013|         37.331415|          -121.8932|    Adobe on Almaden|\n",
      "|[5a5d498991bd3626...|San Jose|        15|  6|         8/7/2013|37.336721000000004|        -121.894074|    San Pedro Square|\n",
      "|[5a5d498991bd3626...|San Jose|        15|  7|         8/7/2013|         37.333798|-121.88694299999999|Paseo de San Antonio|\n",
      "|[5a5d498991bd3626...|San Jose|        15|  8|         8/5/2013|         37.330165|-121.88583100000001| San Salvador at 1st|\n",
      "|[5a5d498991bd3626...|San Jose|        15|  9|         8/5/2013|         37.348742|-121.89471499999999|           Japantown|\n",
      "+--------------------+--------+----------+---+-----------------+------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stationDF.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+------+---------------+------------------+------------+-----------------------------+-----------------+--------------------+------------------+----------------+-------------+------------------------------+------------------+---------------------+-------------------+---------------+------------+-----------------------------+-----------------+--------------------+--------------------+----------------+--------+\n",
      "|                 _id|cloud_cover|     date|events|max_dew_point_f|max_gust_speed_mph|max_humidity|max_sea_level_pressure_inches|max_temperature_f|max_visibility_miles|max_wind_Speed_mph|mean_dew_point_f|mean_humidity|mean_sea_level_pressure_inches|mean_temperature_f|mean_visibility_miles|mean_wind_speed_mph|min_dew_point_f|min_humidity|min_sea_level_pressure_inches|min_temperature_f|min_visibility_miles|precipitation_inches|wind_dir_degrees|zip_code|\n",
      "+--------------------+-----------+---------+------+---------------+------------------+------------+-----------------------------+-----------------+--------------------+------------------+----------------+-------------+------------------------------+------------------+---------------------+-------------------+---------------+------------+-----------------------------+-----------------+--------------------+--------------------+----------------+--------+\n",
      "|[5a5d4ebd91bd3626...|        4.0|8/29/2013|      |           61.0|              28.0|        93.0|                        30.07|             74.0|                10.0|              23.0|            58.0|         75.0|                         30.02|              68.0|                 10.0|               11.0|           56.0|        57.0|                        29.97|             61.0|                10.0|                   0|           286.0|   94107|\n",
      "|[5a5d4ebd91bd3626...|        6.0| 9/2/2013|      |           61.0|              30.0|        93.0|                        29.97|             75.0|                10.0|              23.0|            60.0|         77.0|                         29.94|              69.0|                 10.0|               12.0|           58.0|        61.0|                         29.9|             62.0|                 6.0|                   0|           277.0|   94107|\n",
      "+--------------------+-----------+---------+------+---------------+------------------+------------+-----------------------------+-----------------+--------------------+------------------+----------------+-------------+------------------------------+------------------+---------------------+-------------------+---------------+------------+-----------------------------+-----------------+--------------------+--------------------+----------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherDF.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------+---------------+--------------+--------------------+----+---------------+----------------+--------------------+-----------------+--------+\n",
      "|                 _id|bike_id|duration|       end_date|end_station_id|    end_station_name|  id|     start_date|start_station_id|  start_station_name|subscription_type|zip_code|\n",
      "+--------------------+-------+--------+---------------+--------------+--------------------+----+---------------+----------------+--------------------+-----------------+--------+\n",
      "|[5a5d4ec891bd3626...|    520|      63|8/29/2013 14:14|            66|South Van Ness at...|4576|8/29/2013 14:13|              66|South Van Ness at...|       Subscriber|   94127|\n",
      "|[5a5d4ec891bd3626...|    661|      70|8/29/2013 14:43|            10|  San Jose City Hall|4607|8/29/2013 14:42|              10|  San Jose City Hall|       Subscriber|   95138|\n",
      "|[5a5d4ec891bd3626...|     48|      71|8/29/2013 10:17|            27|Mountain View Cit...|4130|8/29/2013 10:16|              27|Mountain View Cit...|       Subscriber|   97214|\n",
      "|[5a5d4ec891bd3626...|     26|      77|8/29/2013 11:30|            10|  San Jose City Hall|4251|8/29/2013 11:29|              10|  San Jose City Hall|       Subscriber|   95060|\n",
      "|[5a5d4ec891bd3626...|    319|      83|8/29/2013 12:04|            67|      Market at 10th|4299|8/29/2013 12:02|              66|South Van Ness at...|       Subscriber|   94103|\n",
      "+--------------------+-------+--------+---------------+--------------+--------------------+----+---------------+----------------+--------------------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDF.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id', 'bikes_available', 'docks_available', 'station_id', 'time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'bike_id',\n",
       " 'duration',\n",
       " 'end_date',\n",
       " 'end_station_id',\n",
       " 'end_station_name',\n",
       " 'id',\n",
       " 'start_date',\n",
       " 'start_station_id',\n",
       " 'start_station_name',\n",
       " 'subscription_type',\n",
       " 'zip_code']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weekday/Weekend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding day of week column\n",
    "statusDF = statusDF.withColumn('dayofweek',date_format(from_unixtime(unix_timestamp(statusDF[\"time\"][0:10], 'yyyy/MM/dd')),'EEEE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cleaning dayofweek column\n",
    "statusDF = statusDF.withColumn(\"dayofweek\", \n",
    "                    when(col(\"dayofweek\").isNull(), date_format(from_unixtime(unix_timestamp(statusDF[\"time\"][0:10], 'yyyy-MM-dd')),'EEEE')).\n",
    "                        otherwise(col('dayofweek')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|               time|dayofweek|\n",
      "+-------------------+---------+\n",
      "|2013/08/29 12:06:01| Thursday|\n",
      "|2013/08/29 12:07:01| Thursday|\n",
      "|2013/08/29 12:08:01| Thursday|\n",
      "|2013/08/29 12:09:01| Thursday|\n",
      "|2013/08/29 12:10:01| Thursday|\n",
      "+-------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statusDF.select('time','dayofweek').show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding weekend column\n",
    "statusDF = statusDF.withColumn(\"weekend\", when(col('dayofweek') == 'Saturday',1).when(col('dayofweek') == 'Sunday', 1).otherwise(0))\n",
    "#Adding weekday column\n",
    "statusDF = statusDF.withColumn(\"weekday\", when(col('dayofweek') == 'Saturday',0).when(col('dayofweek') == 'Sunday', 0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+-------+\n",
      "|               time|dayofweek|weekend|weekday|\n",
      "+-------------------+---------+-------+-------+\n",
      "|2013/09/01 00:00:02|   Sunday|      1|      0|\n",
      "+-------------------+---------+-------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking output\n",
    "statusDF.select('time','dayofweek','weekend','weekday').where(statusDF.dayofweek == \"Sunday\").show(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Hour of Day/Morning/Afternoon/Evening/Night "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding hourofday column\n",
    "statusDF = statusDF.withColumn('hourofday',statusDF[\"time\"][12:2].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We define morning as the time between 5am and 12pm, afternoon between 12pm and 5pm, evening between 5pm and 11pm and night between 11pm and 5am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding morning column\n",
    "statusDF = statusDF.withColumn(\"morning\", when(col('hourofday').between(5,11),1).otherwise(0))\n",
    "#Adding afternoon column\n",
    "statusDF = statusDF.withColumn(\"afternoon\", when(col('hourofday').between(12,16),1).otherwise(0))\n",
    "#Adding evening column\n",
    "statusDF = statusDF.withColumn(\"evening\", when(col('hourofday').between(17,22),1).otherwise(0))\n",
    "#Adding night column\n",
    "statusDF = statusDF.withColumn(\"night\", when(col('hourofday').between(23,24), 1).when(col('hourofday').between(0,4),1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+---------+-------+-----+\n",
      "|               time|hourofday|morning|afternoon|evening|night|\n",
      "+-------------------+---------+-------+---------+-------+-----+\n",
      "|2013/08/29 12:06:01|       12|      0|        1|      0|    0|\n",
      "|2013/08/29 12:07:01|       12|      0|        1|      0|    0|\n",
      "|2013/08/29 12:08:01|       12|      0|        1|      0|    0|\n",
      "|2013/08/29 12:09:01|       12|      0|        1|      0|    0|\n",
      "|2013/08/29 12:10:01|       12|      0|        1|      0|    0|\n",
      "+-------------------+---------+-------+---------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statusDF.select('time','hourofday','morning','afternoon','evening','night').show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Month/Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding month column\n",
    "statusDF = statusDF.withColumn('month',month(from_unixtime(unix_timestamp(statusDF[\"time\"][0:10], 'yyyy/MM/dd'))))\n",
    "# Adding year column\n",
    "statusDF = statusDF.withColumn('year',year(from_unixtime(unix_timestamp(statusDF[\"time\"][0:10], 'yyyy/MM/dd'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------------+----------+-------------------+---------+-------+-------+---------+-------+---------+-------+-----+-----+----+\n",
      "|                 _id|bikes_available|docks_available|station_id|               time|dayofweek|weekend|weekday|hourofday|morning|afternoon|evening|night|month|year|\n",
      "+--------------------+---------------+---------------+----------+-------------------+---------+-------+-------+---------+-------+---------+-------+-----+-----+----+\n",
      "|[5a5d49a291bd3626...|              2|             25|         2|2013/08/29 12:06:01| Thursday|      0|      1|       12|      0|        1|      0|    0|    8|2013|\n",
      "+--------------------+---------------+---------------+----------+-------------------+---------+-------+-------+---------+-------+---------+-------+-----+-----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statusDF.show(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleaning month column\n",
    "statusDF = statusDF.withColumn(\"month\", \n",
    "                    when(col(\"month\").isNull(), month(from_unixtime(unix_timestamp(statusDF[\"time\"][0:10], 'yyyy-MM-dd')))).\n",
    "                        otherwise(col('month')))\n",
    "#Cleaning year column\n",
    "statusDF = statusDF.withColumn(\"year\", \n",
    "                    when(col(\"year\").isNull(), year(from_unixtime(unix_timestamp(statusDF[\"time\"][0:10], 'yyyy-MM-dd')))).\n",
    "                        otherwise(col('year')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-------+---------+-------+-----+---------+-----+----+\n",
      "|station_id|weekend|weekday|morning|afternoon|evening|night|hourofday|month|year|\n",
      "+----------+-------+-------+-------+---------+-------+-----+---------+-----+----+\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "|         2|      0|      1|      0|        1|      0|    0|       12|    8|2013|\n",
      "+----------+-------+-------+-------+---------+-------+-----+---------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Features so far\n",
    "statusDF.select('station_id', 'weekend', 'weekday', 'morning', 'afternoon', 'evening', 'night', 'hourofday', 'month','year').show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_id=Row(oid='5a5d49a291bd3626222c4ba7'), bikes_available=2, docks_available=25, station_id=2, time='2013/08/29 12:06:01', dayofweek='Thursday', weekend=0, weekday=1, hourofday=12, morning=0, afternoon=1, evening=0, night=0, month=8, year=2013)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sqlContext.sql(\"drop table if exists statusDF\")\n",
    "#statusDF.write.saveAsTable('statusDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_id=Row(oid='5a5d4b6591bd362622b233ec'), bikes_available=4, docks_available=11, station_id=16, time='2015-01-09 18:04:02', dayofweek='Friday', weekend=0, weekday=1, hourofday=18, morning=0, afternoon=0, evening=1, night=0, month=1, year=2015)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from statusDF limit 1\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average number of bikes/docks available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statusDF_avg = sqlContext.sql(\"\"\"\n",
    "SELECT station_id, weekend, weekday, hourofday, month, year, dayofweek, morning, afternoon, evening, night,\n",
    "avg(bikes_available) AS avg_bikes_available, \n",
    "avg(docks_available) AS avg_docks_available\n",
    "FROM statusDF\n",
    "GROUP BY 1,2,3,4,5,6,7,8,9,10,11\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(station_id=16, weekend=0, weekday=1, hourofday=9, month=2, year=2015, dayofweek='Monday', morning=1, afternoon=0, evening=0, night=0, avg_bikes_available=6.629166666666666, avg_docks_available=8.370833333333334)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statusDF_avg.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define events with \"fog\" as 1, \"rain\" as 2, \"fog-rain\" as 3 and \"rain-thunderstorms\" as 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weatherDF = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb://127.0.0.1/msan697.weather\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weatherDF = weatherDF.withColumn(\"events\", when(col('events') == 'Fog', 1).\\\n",
    "                                 when(col('events').like ('%ain'),2).\\\n",
    "                                 when(col('events') == 'Fog-Rain',3).\\\n",
    "                                 when(col('events') == 'Rain-Thunderstorm',4).\\\n",
    "                                 otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Day of week/Weekend/Weekday/Month/Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding day of week column\n",
    "weatherDF = weatherDF.withColumn('dayofweek',date_format(from_unixtime(unix_timestamp(weatherDF[\"date\"], 'M/dd/yyyy')),'EEEE'))\n",
    "#Adding weekend column\n",
    "weatherDF = weatherDF.withColumn(\"weekend\", when(col('dayofweek') == 'Saturday',1).when(col('dayofweek') == 'Sunday', 1).otherwise(0))\n",
    "#Adding weekday column\n",
    "weatherDF = weatherDF.withColumn(\"weekday\", when(col('dayofweek') == 'Saturday',0).when(col('dayofweek') == 'Sunday', 0).otherwise(1))\n",
    "#Adding month column\n",
    "weatherDF = weatherDF.withColumn('month',month(from_unixtime(unix_timestamp(weatherDF[\"date\"], 'M/dd/yyyy'))))\n",
    "# Adding year column\n",
    "weatherDF = weatherDF.withColumn('year',year(from_unixtime(unix_timestamp(weatherDF[\"date\"], 'M/dd/yyyy'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+-------+-----+----+\n",
      "|     date|dayofweek|weekend|weekday|month|year|\n",
      "+---------+---------+-------+-------+-----+----+\n",
      "|8/29/2013| Thursday|      0|      1|    8|2013|\n",
      "| 9/2/2013|   Monday|      0|      1|    9|2013|\n",
      "| 9/3/2013|  Tuesday|      0|      1|    9|2013|\n",
      "| 9/4/2013|Wednesday|      0|      1|    9|2013|\n",
      "| 9/5/2013| Thursday|      0|      1|    9|2013|\n",
      "+---------+---------+-------+-------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherDF.select('date','dayofweek','weekend','weekday','month','year').show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Averaged weather variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-62-2f7d0d6a9f2a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-62-2f7d0d6a9f2a>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    .agg(avg(\"min_temperature_f\").alias(\"min_temperature_f\"))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "weatherDF = weatherDF.drop(\"_id\", \"date\").groupBy(\"zip_code\", \"dayofweek\", \"month\",\"year\",\"weekend\",\"weekday\").agg(avg(\"max_temperature_f\").alias(\"max_temperature_f\"), \n",
    "                                                                                                                   avg(\"mean_temperature_f\").alias(\"mean_temperature_f\"),\n",
    "                                                                                                                   avg(\"min_temperature_f\").alias(\"min_temperature_f\"), \n",
    "                                                                                                                   avg(\"max_dew_point_f\").alias(\"max_dew_point_f\"),\n",
    "                                                                                                                   avg(\"mean_dew_point_f\").alias(\"mean_dew_point_f\"), \n",
    "                                                                                                                   avg(\"min_dew_point_f\").alias(\"min_dew_point_f\"),\n",
    "                                                                                                                   avg(\"max_humidity\").alias(\"max_humidity\"), \n",
    "                                                                                                                   avg(\"mean_humidity\").alias(\"mean_humidity\"),\n",
    "                                                                                                                   avg(\"min_humidity\").alias(\"min_humidity\"), \n",
    "                                                                                                                   avg(\"max_sea_level_pressure_inches\").alias(\"max_sea_level_pressure_inches\"),\n",
    "                                                                                                                   avg(\"mean_sea_level_pressure_inches\").alias(\"mean_sea_level_pressure_inches\"),\n",
    "                                                                                                                   avg(\"min_sea_level_pressure_inches\").alias(\"min_sea_level_pressure_inches\"),\n",
    "                                                                                                                   avg(\"max_visibility_miles\").alias(\"max_visibility_miles\"), \n",
    "                                                                                                                   avg(\"mean_visibility_miles\").alias(\"mean_visibility_miles\"),\n",
    "                                                                                                                   avg(\"min_visibility_miles\").alias(\"min_visibility_miles\"), \n",
    "                                                                                                                   avg(\"max_wind_Speed_mph\").alias(\"max_wind_Speed_mph\"),\n",
    "                                                                                                                   avg(\"mean_wind_speed_mph\").alias(\"mean_wind_speed_mph\"), \n",
    "                                                                                                                   avg(\"max_gust_speed_mph\").alias(\"max_gust_speed_mph\"),\n",
    "                                                                                                                   avg(\"precipitation_inches\").alias(\"precipitation_inches\"), \n",
    "                                                                                                                   avg(\"cloud_cover\").alias(\"cloud_cover\"),\n",
    "                                                                                                                   avg(\"wind_dir_degrees\").alias(\"wind_dir_degrees\"),\n",
    "                                                                                                                   avg(\"events\").alias(\"events\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+---------+------+---------------+------------------+------------+-----------------------------+-----------------+--------------------+------------------+----------------+-------------+------------------------------+------------------+---------------------+-------------------+---------------+------------+-----------------------------+-----------------+--------------------+--------------------+----------------+--------+---------+-------+-------+-----+----+\n",
      "|                 _id|cloud_cover|     date|events|max_dew_point_f|max_gust_speed_mph|max_humidity|max_sea_level_pressure_inches|max_temperature_f|max_visibility_miles|max_wind_Speed_mph|mean_dew_point_f|mean_humidity|mean_sea_level_pressure_inches|mean_temperature_f|mean_visibility_miles|mean_wind_speed_mph|min_dew_point_f|min_humidity|min_sea_level_pressure_inches|min_temperature_f|min_visibility_miles|precipitation_inches|wind_dir_degrees|zip_code|dayofweek|weekend|weekday|month|year|\n",
      "+--------------------+-----------+---------+------+---------------+------------------+------------+-----------------------------+-----------------+--------------------+------------------+----------------+-------------+------------------------------+------------------+---------------------+-------------------+---------------+------------+-----------------------------+-----------------+--------------------+--------------------+----------------+--------+---------+-------+-------+-----+----+\n",
      "|[5a5d4ebd91bd3626...|        4.0|8/29/2013|     0|           61.0|              28.0|        93.0|                        30.07|             74.0|                10.0|              23.0|            58.0|         75.0|                         30.02|              68.0|                 10.0|               11.0|           56.0|        57.0|                        29.97|             61.0|                10.0|                   0|           286.0|   94107| Thursday|      0|      1|    8|2013|\n",
      "+--------------------+-----------+---------+------+---------------+------------------+------------+-----------------------------+-----------------+--------------------+------------------+----------------+-------------+------------------------------+------------------+---------------------+-------------------+---------------+------------+-----------------------------+-----------------+--------------------+--------------------+----------------+--------+---------+-------+-------+-----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherDF.show(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Station Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add age of the docks\n",
    "stationDF = stationDF.withColumn('age', \\\n",
    "               datediff(from_unixtime(unix_timestamp(date_format(current_date(), \"M/d/y\"), 'MM/dd/yyy')),\\\n",
    "                              from_unixtime(unix_timestamp(stationDF['installation_date'], 'MM/dd/yyy'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stationDF.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trip Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Day of week/Hour/Weekend/Weekday/Month/Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tripDF = tripDF.withColumn('start_date', concat(col('start_date'),lit(':00'))).withColumn('end_date', concat(col('end_date'),lit(':00')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tripDF = tripDF.withColumn('dayofweek',date_format(from_unixtime(unix_timestamp('start_date', 'MM/dd/yyy HH:mm:ss')),'EEEE'))\\\n",
    ".withColumn(\"weekend\", when(col('dayofweek') == 'Saturday',1).when(col('dayofweek') == 'Sunday', 1).otherwise(0))\\\n",
    ".withColumn(\"weekday\", when(col('dayofweek') == 'Saturday',0).when(col('dayofweek') == 'Sunday', 0).otherwise(1))\\\n",
    ".withColumn('hourofday',hour(from_unixtime(unix_timestamp('start_date', 'MM/dd/yyy HH:mm:ss'))))\\\n",
    ".withColumn('month',month(from_unixtime(unix_timestamp('start_date', 'MM/dd/yyy HH:mm:ss'))))\\\n",
    ".withColumn('year',year(from_unixtime(unix_timestamp('start_date', 'MM/dd/yyy HH:mm:ss'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tripDF.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of outgoing/incoming bikes at a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outgoing_bikesDF = tripDF.groupBy('zip_code', 'start_station_id', 'hourofday', 'dayofweek', 'weekend', 'weekday', 'month', 'year').agg(count('*').alias('outgoing_bikes_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incoming_bikesDF = tripDF.groupBy('zip_code', 'end_station_id', 'hourofday' , 'dayofweek', 'weekend', 'weekday', 'month', 'year').agg(count('*').alias('incoming_bikes_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sqlContext.sql(\"drop table if exists outgoing_bikesDF\")\n",
    "#sqlContext.sql(\"drop table if exists incoming_bikesDF\")\n",
    "#outgoing_bikesDF.write.saveAsTable(\"outgoing_bikesDF\")\n",
    "#incoming_bikesDF.write.saveAsTable(\"incoming_bikesDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incoming_bikesDF.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tripDF_final = sqlContext.sql(\"\"\"\n",
    "SELECT outgoing_bikesDF.zip_code AS zip_code,\n",
    "start_station_id,\n",
    "end_station_id,\n",
    "outgoing_bikesDF.hourofday AS hourofday,\n",
    "outgoing_bikesDF.dayofweek AS dayofweek,\n",
    "outgoing_bikesDF.weekend AS weekend,\n",
    "outgoing_bikesDF.weekday AS weekday,\n",
    "outgoing_bikesDF.month AS month,\n",
    "outgoing_bikesDF.year AS year,\n",
    "outgoing_bikes_count,\n",
    "incoming_bikes_count\n",
    "FROM outgoing_bikesDF LEFT JOIN incoming_bikesDF \n",
    "ON outgoing_bikesDF.start_station_id = incoming_bikesDF.end_station_id\n",
    "AND outgoing_bikesDF.hourofday = incoming_bikesDF.hourofday\n",
    "AND outgoing_bikesDF.dayofweek = incoming_bikesDF.dayofweek\n",
    "AND outgoing_bikesDF.weekend = incoming_bikesDF.weekend\n",
    "AND outgoing_bikesDF.weekday = incoming_bikesDF.weekday\n",
    "AND outgoing_bikesDF.month = incoming_bikesDF.month\n",
    "AND outgoing_bikesDF.year = incoming_bikesDF.year\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Incoming traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define incoming traffic as the *number of incoming bikes - number of outgoing bikes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tripDF_final = tripDF_final.withColumn(\"incoming_traffic\", tripDF_final[\"incoming_bikes_count\"] - tripDF_final[\"outgoing_bikes_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first join the *trips* table with *station* table based on the end station of the trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df = stationDF.join(tripDF_final, stationDF.id == tripDF_final.end_station_id, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df = joined_df.drop(\"start_station_id\", \"end_station_id\", \"_id\", \"installation_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df = joined_df.withColumnRenamed(\"id\", \"station_id\").withColumnRenamed(\"name\", \"station_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we join the *joined trips* table, with *status* table based on the station id, hour, day of week, weekend/weekday, month and year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df2 = joined_df.join(statusDF_avg, [\"station_id\", \"hourofday\", \"dayofweek\", \"weekend\", \"weekday\", \"month\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df2 = joined_df2.withColumnRenamed(\"dock_count\", \"total_capacity\").withColumnRenamed(\"age\", \"station_age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we join the *weather* table to the above joined table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_joined = joined_df2.join(weatherDF, [\"zip_code\", \"dayofweek\", \"weekend\", \"weekday\", \"month\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_joined.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Final features\n",
    "final_joined.columns"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
